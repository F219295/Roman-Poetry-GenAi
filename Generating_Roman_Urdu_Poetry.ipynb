{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s73QQ_sL5Qas"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "import random\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Roman-Urdu-Poetry.csv\")  # Use the correct file name\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Normalize Unicode characters (removes accents and diacritics)\n",
        "    text = ''.join(c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c))\n",
        "\n",
        "    # Remove unwanted characters except for basic punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s.,?!]\", \"\", text)\n",
        "\n",
        "    # Remove dots within words (fix ja.ega -> jaega, ro.ega -> roega)\n",
        "    text = re.sub(r\"\\.(?=\\w)\", \"\", text)\n",
        "\n",
        "    # Replace multiple spaces and newlines with a single space\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply cleaning function to poetry column\n",
        "df[\"Poetry\"] = df[\"Poetry\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "MuidaYiU-n9D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['Poetry'])\n",
        "sequences = tokenizer.texts_to_sequences(df['Poetry'])\n",
        "max_sequence_length = 20\n",
        "\n",
        "input_sequences = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, min(len(seq), max_sequence_length)):\n",
        "        input_sequences.append(seq[:i+1])\n",
        "\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index) + 1)"
      ],
      "metadata": {
        "id": "BzGoawWv-0ej"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_sequence_length - 1),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    LSTM(128),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "8NlNpN4O-7Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd24ed8e-bcc0-46be-b183-e2d8ba652e72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "model.save(\"Poetry_model2.h5\")"
      ],
      "metadata": {
        "id": "XEXeGZlH-64r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e58e259-5322-4133-c8bc-ed278c55eda7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6174 - loss: 1.6716\n",
            "Epoch 2/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.6256 - loss: 1.6366\n",
            "Epoch 3/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.6404 - loss: 1.5572\n",
            "Epoch 4/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6496 - loss: 1.5156\n",
            "Epoch 5/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.6583 - loss: 1.4895\n",
            "Epoch 6/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.6732 - loss: 1.4055\n",
            "Epoch 7/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.6823 - loss: 1.3681\n",
            "Epoch 8/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.6858 - loss: 1.3369\n",
            "Epoch 9/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.6930 - loss: 1.3296\n",
            "Epoch 10/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7042 - loss: 1.2592\n",
            "Epoch 11/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.7158 - loss: 1.2063\n",
            "Epoch 12/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7226 - loss: 1.1922\n",
            "Epoch 13/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7276 - loss: 1.1521\n",
            "Epoch 14/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7438 - loss: 1.1004\n",
            "Epoch 15/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7457 - loss: 1.0792\n",
            "Epoch 16/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7584 - loss: 1.0294\n",
            "Epoch 17/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7651 - loss: 1.0069\n",
            "Epoch 18/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7713 - loss: 0.9705\n",
            "Epoch 19/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.7780 - loss: 0.9463\n",
            "Epoch 20/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7852 - loss: 0.9139\n",
            "Epoch 21/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7972 - loss: 0.8763\n",
            "Epoch 22/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7974 - loss: 0.8571\n",
            "Epoch 23/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8075 - loss: 0.8236\n",
            "Epoch 24/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8105 - loss: 0.8023\n",
            "Epoch 25/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8156 - loss: 0.7851\n",
            "Epoch 26/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8169 - loss: 0.7558\n",
            "Epoch 27/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.8313 - loss: 0.7183\n",
            "Epoch 28/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8312 - loss: 0.7120\n",
            "Epoch 29/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8356 - loss: 0.7038\n",
            "Epoch 30/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.8475 - loss: 0.6525\n",
            "Epoch 31/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8407 - loss: 0.6565\n",
            "Epoch 32/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8456 - loss: 0.6489\n",
            "Epoch 33/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8549 - loss: 0.6097\n",
            "Epoch 34/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8607 - loss: 0.5848\n",
            "Epoch 35/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8709 - loss: 0.5665\n",
            "Epoch 36/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8557 - loss: 0.5917\n",
            "Epoch 37/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8641 - loss: 0.5504\n",
            "Epoch 38/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.8835 - loss: 0.4997\n",
            "Epoch 39/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.8805 - loss: 0.5094\n",
            "Epoch 40/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8842 - loss: 0.4765\n",
            "Epoch 41/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8864 - loss: 0.4832\n",
            "Epoch 42/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8803 - loss: 0.4993\n",
            "Epoch 43/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8891 - loss: 0.4546\n",
            "Epoch 44/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8879 - loss: 0.4732\n",
            "Epoch 45/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8960 - loss: 0.4389\n",
            "Epoch 46/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9007 - loss: 0.4261\n",
            "Epoch 47/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9016 - loss: 0.4005\n",
            "Epoch 48/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9014 - loss: 0.4185\n",
            "Epoch 49/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9034 - loss: 0.3993\n",
            "Epoch 50/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9044 - loss: 0.3972\n",
            "Epoch 51/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9178 - loss: 0.3521\n",
            "Epoch 52/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9142 - loss: 0.3536\n",
            "Epoch 53/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9100 - loss: 0.3645\n",
            "Epoch 54/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9169 - loss: 0.3438\n",
            "Epoch 55/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8942 - loss: 0.4157\n",
            "Epoch 56/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9200 - loss: 0.3303\n",
            "Epoch 57/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9368 - loss: 0.2787\n",
            "Epoch 58/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9364 - loss: 0.2722\n",
            "Epoch 59/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9301 - loss: 0.2964\n",
            "Epoch 60/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9266 - loss: 0.3089\n",
            "Epoch 61/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9197 - loss: 0.3388\n",
            "Epoch 62/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9154 - loss: 0.3482\n",
            "Epoch 63/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9300 - loss: 0.2936\n",
            "Epoch 64/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9214 - loss: 0.3258\n",
            "Epoch 65/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9236 - loss: 0.3097\n",
            "Epoch 66/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9380 - loss: 0.2577\n",
            "Epoch 67/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9406 - loss: 0.2483\n",
            "Epoch 68/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9188 - loss: 0.3205\n",
            "Epoch 69/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9227 - loss: 0.3034\n",
            "Epoch 70/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9342 - loss: 0.2662\n",
            "Epoch 71/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9181 - loss: 0.3211\n",
            "Epoch 72/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9295 - loss: 0.2848\n",
            "Epoch 73/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9335 - loss: 0.2779\n",
            "Epoch 74/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9378 - loss: 0.2512\n",
            "Epoch 75/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.9370 - loss: 0.2570\n",
            "Epoch 76/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9390 - loss: 0.2478\n",
            "Epoch 77/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9316 - loss: 0.2656\n",
            "Epoch 78/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9302 - loss: 0.2774\n",
            "Epoch 79/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.9351 - loss: 0.2586\n",
            "Epoch 80/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.9402 - loss: 0.2361\n",
            "Epoch 81/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9387 - loss: 0.2390\n",
            "Epoch 82/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9354 - loss: 0.2587\n",
            "Epoch 83/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9352 - loss: 0.2450\n",
            "Epoch 84/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9407 - loss: 0.2333\n",
            "Epoch 85/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.9478 - loss: 0.2114\n",
            "Epoch 86/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9362 - loss: 0.2466\n",
            "Epoch 87/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9361 - loss: 0.2389\n",
            "Epoch 88/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.9410 - loss: 0.2308\n",
            "Epoch 89/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9425 - loss: 0.2265\n",
            "Epoch 90/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9447 - loss: 0.2087\n",
            "Epoch 91/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9372 - loss: 0.2427\n",
            "Epoch 92/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9300 - loss: 0.2596\n",
            "Epoch 93/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9398 - loss: 0.2265\n",
            "Epoch 94/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9490 - loss: 0.2029\n",
            "Epoch 95/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.9491 - loss: 0.1876\n",
            "Epoch 96/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9415 - loss: 0.2211\n",
            "Epoch 97/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9368 - loss: 0.2316\n",
            "Epoch 98/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.9396 - loss: 0.2234\n",
            "Epoch 99/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.9524 - loss: 0.1924\n",
            "Epoch 100/100\n",
            "\u001b[1m779/779\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.9476 - loss: 0.2175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_poem(prompt, num_lines, words_per_line, temperature):\n",
        "    \"\"\"\n",
        "    Generates a poem based on the given prompt.\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (str): The initial word or phrase to start the poem.\n",
        "    - num_lines (int): Number of lines in the generated poem.\n",
        "    - words_per_line (int): Number of words per line.\n",
        "    - temperature (float): Controls the randomness of predictions.\n",
        "\n",
        "    Returns:\n",
        "    - str: The generated poem.\n",
        "    \"\"\"\n",
        "    poem = []\n",
        "    current_word = prompt.lower()\n",
        "\n",
        "    for _ in range(num_lines):\n",
        "        line = current_word  # Start each line with the prompt word\n",
        "\n",
        "        for _ in range(words_per_line - 1):\n",
        "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "            token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding='pre')\n",
        "\n",
        "            predictions = model.predict(token_list, verbose=0)[0]\n",
        "            predictions = np.log(predictions + 1e-10) / temperature\n",
        "            exp_preds = np.exp(predictions)\n",
        "            predictions = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "            sorted_indices = np.argsort(predictions)[-5:]  # Top 5 words\n",
        "            possible_words = [tokenizer.index_word.get(idx, None) for idx in sorted_indices if idx in tokenizer.index_word]\n",
        "            possible_words = [word for word in possible_words if word is not None]\n",
        "\n",
        "            if possible_words:\n",
        "                word = random.choices(possible_words, weights=predictions[sorted_indices])[0]\n",
        "            else:\n",
        "                break\n",
        "\n",
        "            line += \" \" + word\n",
        "            current_word = word\n",
        "\n",
        "        poem.append(line.capitalize())\n",
        "\n",
        "    return \"\\n\".join(poem)\n",
        "\n",
        "# Get user input\n",
        "prompt = input(\"Enter the prompt for the poem: \")\n",
        "num_lines = int(input(\"Enter the number of lines: \"))\n",
        "words_per_line = int(input(\"Enter the number of words per line: \"))\n",
        "temperature = float(input(\"Enter the temperature (e.g., 0.8 for creativity): \"))\n",
        "\n",
        "# Generate and print the poem\n",
        "poem = generate_poem(prompt, num_lines, words_per_line, temperature)\n",
        "print(\"\\nGenerated Poem:\\n\")\n",
        "print(poem)"
      ],
      "metadata": {
        "id": "ncKOKAg7-6dF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "ebb004c9-73a0-4f4f-b3fa-6ccfaec59a5e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5dbcb18a3784>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Get user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the prompt for the poem: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mnum_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the number of lines: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mwords_per_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the number of words per line: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "# Load trained model\n",
        "model = load_model(\"Poetry_model2.h5\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Roman-Urdu-Poetry.csv\")\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = ''.join(c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c))\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s.,?!]\", \"\", text)\n",
        "    text = re.sub(r\"\\.(?=\\w)\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Apply cleaning function\n",
        "df[\"Poetry\"] = df[\"Poetry\"].apply(clean_text)\n",
        "\n",
        "# Tokenization\n",
        "max_sequence_length = 20\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['Poetry'])\n",
        "sequences = tokenizer.texts_to_sequences(df['Poetry'])\n",
        "\n",
        "# Padding sequences\n",
        "input_sequences = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, min(len(seq), max_sequence_length)):\n",
        "        input_sequences.append(seq[:i+1])\n",
        "\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index) + 1)\n",
        "\n",
        "# Poetry generation function\n",
        "def generate_poem(prompt, num_lines, words_per_line, temperature):\n",
        "    poem = []\n",
        "    current_word = prompt.lower()\n",
        "\n",
        "    for _ in range(num_lines):\n",
        "        line = current_word\n",
        "        for _ in range(words_per_line - 1):\n",
        "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "            token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding='pre')\n",
        "\n",
        "            predictions = model.predict(token_list, verbose=0)[0]\n",
        "            predictions = np.log(predictions + 1e-10) / temperature\n",
        "            exp_preds = np.exp(predictions)\n",
        "            predictions = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "            sorted_indices = np.argsort(predictions)[-5:]\n",
        "            possible_words = [tokenizer.index_word.get(idx, None) for idx in sorted_indices if idx in tokenizer.index_word]\n",
        "            possible_words = [word for word in possible_words if word is not None]\n",
        "\n",
        "            if possible_words:\n",
        "                word = random.choices(possible_words, weights=predictions[sorted_indices])[0]\n",
        "            else:\n",
        "                break\n",
        "\n",
        "            line += \" \" + word\n",
        "            current_word = word\n",
        "\n",
        "        poem.append(line.capitalize())\n",
        "\n",
        "    return \"\\n\".join(poem)\n",
        "\n",
        "# Gradio UI with custom CSS for full-page view\n",
        "with gr.Blocks(theme=\"soft\") as iface:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        <h1 style=\"text-align: center; font-size: 2rem; margin-top: 20px;\">✨ Roman Urdu Poetry Generator ✨</h1>\n",
        "        <p style=\"text-align: center; font-size: 1rem; margin-bottom: 30px;\">Enter a word or phrase, and let the AI generate poetic lines in Roman Urdu. 🎶</p>\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Full-page layout with centered content\n",
        "    with gr.Row(elem_id=\"main-row\", scale=1):\n",
        "        with gr.Column(elem_id=\"inputs-column\", scale=1):\n",
        "            prompt = gr.Textbox(label=\"Enter Prompt\", placeholder=\"e.g., Ishq, Dard, Khwab...\", interactive=True, lines=1)\n",
        "            num_lines = gr.Slider(1, 10, value=4, step=1, label=\"Number of Lines\")\n",
        "            words_per_line = gr.Slider(3, 10, value=5, step=1, label=\"Words per Line\")\n",
        "            temperature = gr.Slider(0.1, 2.0, value=0.8, step=0.1, label=\"Creativity Level (Temperature)\")\n",
        "            generate_button = gr.Button(\"Generate Poetry 🎤\", variant=\"primary\", size=\"sm\")  # Default small button\n",
        "\n",
        "        with gr.Column(elem_id=\"output-column\", scale=1):\n",
        "            output_poem = gr.Textbox(label=\"Generated Poem\", interactive=False, lines=6)\n",
        "\n",
        "    # Add custom CSS to ensure full-page view and responsiveness\n",
        "    iface.css = \"\"\"\n",
        "    .gradio-container {\n",
        "        height: 85vh;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        justify-content: center;\n",
        "    }\n",
        "    #main-row {\n",
        "        height: 80%;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        justify-content: center;\n",
        "        align-items: center;\n",
        "    }\n",
        "    #inputs-column {\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        justify-content: center;\n",
        "        align-items: center;\n",
        "        width: 100%;\n",
        "    }\n",
        "    #output-column {\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        justify-content: center;\n",
        "        align-items: center;\n",
        "        width: 100%;\n",
        "    }\n",
        "    .gr-button-primary {\n",
        "        padding-left: 20px;\n",
        "        padding-right: 20px;\n",
        "        font-size: 1rem;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    generate_button.click(generate_poem, inputs=[prompt, num_lines, words_per_line, temperature], outputs=output_poem)\n",
        "\n",
        "# Launch app\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "QTjCdPCk7WzP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "26bf8570-b19c-444e-d40d-093b87889a39"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7a3be70a2b88d3d2de.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7a3be70a2b88d3d2de.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}